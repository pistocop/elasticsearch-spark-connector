{"cells":[{"cell_type":"markdown","id":"4803ee76-6b31-42a8-b8c2-994676ee361e","metadata":{},"source":["# Dataset builder\n","> Create and store on GCS random vectors"]},{"cell_type":"markdown","id":"50ee2b96-9cc4-4cef-aa62-eb307aa0c62d","metadata":{},"source":["## Spark cluster info"]},{"cell_type":"code","execution_count":null,"id":"cb1aec22-270b-4641-8bd7-6fb2c8e583e9","metadata":{},"outputs":[],"source":["# Check number of workers VM\n","sc = spark._jsc.sc()\n","n_workers =  len([executor.host() for executor in sc.statusTracker().getExecutorInfos() ]) -1\n","n_workers"]},{"cell_type":"code","execution_count":null,"id":"20a66426-c90f-4bc7-ab58-2d0a62a479ce","metadata":{},"outputs":[],"source":["# Check spark version\n","spark"]},{"cell_type":"markdown","id":"07dc1e70-bda3-4d63-a0f6-2768f19d3c7f","metadata":{},"source":["## Inputs data"]},{"cell_type":"code","execution_count":null,"id":"8e060097-88f7-417f-9bee-e1c4640914c7","metadata":{},"outputs":[],"source":["# Replace the following variables with your values:\n","EMB_N = 1_000_000\n","EMB_DIM = 768\n","EMB_PATH = \"gs://test-project-bucket/testzone/20231015-rnd/\""]},{"cell_type":"markdown","id":"e6775e30-03b5-4449-be63-71b08b70ee06","metadata":{},"source":["---"]},{"cell_type":"markdown","id":"625ad43e-bf27-45cf-b87a-5df70dbcb318","metadata":{},"source":["## Generate mock data"]},{"cell_type":"code","execution_count":null,"id":"7414f986-16fe-450a-aa2c-0becc225aa58","metadata":{},"outputs":[],"source":["data = [n for n in range(EMB_N)]"]},{"cell_type":"code","execution_count":null,"id":"607f5dd7-f572-4c80-8e83-6f8ab4e15aed","metadata":{},"outputs":[],"source":["from pyspark.sql import types as t\n","from pyspark.sql.functions import lit, udf\n","\n","df = spark.createDataFrame(data, t.IntegerType()).toDF(\"emb_id\")\n","df = df.withColumn(\"embedding\", lit(None))"]},{"cell_type":"code","execution_count":null,"id":"1b1c6d1c-83de-46f2-94f7-aeb34803cc98","metadata":{},"outputs":[],"source":["num_partitions = 6 # Adjust this value based on your resources\n","df = df.repartition(num_partitions)"]},{"cell_type":"code","execution_count":null,"id":"e07b8083-33d4-4fcb-86eb-f64ec163fcdb","metadata":{},"outputs":[],"source":["import random\n","from math import sqrt\n","\n","def generate_vector(_empty_value):\n","    vector = [random.random() for _ in range(EMB_DIM)]\n","    norm = sqrt(sum(x**2 for x in vector))\n","    return [x / norm for x in vector]\n","\n","generate_vector_udf = udf(generate_vector, t.ArrayType(t.DoubleType()))\n","df = df.withColumn(\"embedding\", generate_vector_udf(df[\"embedding\"]))"]},{"cell_type":"code","execution_count":null,"id":"58934cdd-0770-424c-b49d-9e760eef7f9c","metadata":{},"outputs":[],"source":["df.write.mode('overwrite').parquet(EMB_PATH)"]},{"cell_type":"markdown","id":"857907cb-d956-4884-a333-840793e2cb57","metadata":{},"source":["---"]},{"cell_type":"markdown","id":"2e95133b-2143-4c8e-a5a1-2131c98feaac","metadata":{},"source":["## ~ end"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}
